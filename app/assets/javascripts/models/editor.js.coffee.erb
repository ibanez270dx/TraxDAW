####################################################
# TRAX.Editor
#   CoffeeScript "class" defining the Editor object.
#
####################################################

# Not Recording :: Microphone -> VolumeNode -> AnalyserNode -> ScriptProcessor -> Destination
#
# Recording :: Microphone -> VolumeNode -> AnalyserNode -> ScriptProcessor -> Recorder -> Destination

@TRAX ||= {}
@TRAX.Editor = class Editor

  track: undefined

  constructor: (editor, options) ->
    @editor = editor
    @liveWaveform = @editor.find('#live-waveform')

    @bufferSize = 2048
    @sampleRate = 44100
    @bufferSource = undefined
    @stream = undefined
    @currentTrackId = 0

    [@micRunning, @isRecording, @isPlaying] = [false, false, false]
    [@width, @height, @cursorPosition] = [0, 0, 0]
    @chromaOrange = new chroma.scale(["#00ff00", "#e0e000", "#ff7f00", "#b60101"])
    
    @controls =
      power: @editor.find('nav li#power')
      microphone: @editor.find('nav li#microphone')
      metronome: @editor.find('nav li#metronome')
      record: @editor.find('nav li#record')
      playback: @editor.find('nav li#playback')

    # Setup Web Audio API
    @context = new webkitAudioContext()
    @_setupNodes()
    @_setupAudioHandler()

    # Create Workspace
    @workspace = new TRAX.Workspace(@context, @editor.find('#workspace'))

    # Create a track to start
    @workspace.createTrack()

    # Initialize Editor
    $('nav li.disabled input').prop('disabled', true)
    @_setupClickHandlers()

  ############################################################################################################
  # Web Audio API   
  ############################################################################################################

  _setupNodes: =>
    # Script Processer Node
    # This interface is an AudioNode which can generate, process, or analyse audio directly using JavaScript.
    # https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/specification.html#ScriptProcessorNode
    @scriptProcessor = @context.createScriptProcessor(2048, 2, 2)
    @scriptProcessor.connect(@context.destination)

    # Analyser Node
    # This interface represents a node which is able to provide real-time frequency and time-domain 
    # analysis information. The audio stream will be passed un-processed from input to output.
    # https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/specification.html#AnalyserNode-section
    @analyser = @context.createAnalyser()
    @analyser.smoothingTimeConstant = 0
    @analyser.fftSize = 512
    @analyser.connect(@scriptProcessor)

    # Gain Node
    # This interface is an AudioNode with a single input and single output. It multiplies the input audio 
    # signal by the (possibly time-varying) gain attribute, copying the result to the output. By default, 
    # it will take the input and pass it through to the output unchanged, which represents a constant gain 
    # change of 1.
    # https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/specification.html#GainNode
    @gain = @context.createGain()
    @gain.connect(@analyser)

  ############################################################################################################
  # Audio Processing   
  ############################################################################################################

  # AudioProcessingEvent Interface
  # This is an Event object which is dispatched to ScriptProcessorNode nodes. The event handler processes 
  # audio from the input (if any) by accessing the audio data from the inputBuffer attribute. The audio data 
  # which is the result of the processing (or the synthesized data if there are no inputs) is then placed into
  # the outputBuffer.
  # https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/specification.html#AudioProcessingEvent-section
  _setupAudioHandler: =>
    @scriptProcessor.onaudioprocess = (event) =>
      array = new Uint8Array(@analyser.frequencyBinCount)
      @analyser.getByteTimeDomainData(array)

      if @micRunning
        @_drawLiveWaveform(array) 

      if @isRecording
        # We clone the samples and set Track channels
        leftChannel = event.inputBuffer.getChannelData(0)
        rightChannel = event.inputBuffer.getChannelData(1)
        @workspace.currentTrack.leftChannel.push(new Float32Array(leftChannel))
        @workspace.currentTrack.rightChannel.push(new Float32Array(rightChannel))
        
        # Set Buffer Length and Track duration
        @workspace.currentTrack.length += event.inputBuffer.length
        @workspace.currentTrack.duration += event.inputBuffer.duration

        # Draw Canvas
        @workspace.currentTrack.draw(array)

      if @isPlaying
        console.log "it's playing!"

  ############################################################################################################
  # HTML5 Canvases   
  ############################################################################################################

  _drawLiveWaveform: (array) =>
    ctx = @liveWaveform[0].getContext("2d")
    ctx.clearRect(0, 0, 100, 35)

    for i in [0..array.length]
      value = array[i]
      ctx.fillStyle = @chromaOrange(value / 255).hex()
      ctx.fillRect((i * 100) / 255, (value / 2) - 45, 1, 1)

  ############################################################################################################
  # Editor Methods   
  ############################################################################################################

  enableMicrophone: =>
    @controls['microphone'].removeClass('disabled')
    @controls['microphone'].find('input').prop('disabled', false)

  disableMicrophone: =>
    @controls['microphone'].addClass('disabled')
    @controls['microphone'].find('input').prop('disabled', true)

  startMicrophone: =>
    @micSource = @context.createMediaStreamSource(@stream)
    @micSource.connect(@gain)
    @micRunning = true
    @enableRecord()

  stopMicrophone: =>
    @micRunning = false
    @micSource.disconnect(@volume)    
    @liveWaveform.get()[0].getContext("2d").clearRect(0, 0, 100, 35)
    @disableRecord()

  enableMetronome: =>
    @controls['metronome'].removeClass('disabled')
    @controls['metronome'].find('input').prop('disabled', false)

  disableMetronome: =>
    @controls['metronome'].addClass('disabled')
    @controls['metronome'].find('input').prop('disabled', true)

  enableRecord: =>
    @controls['record'].removeClass('disabled')
    @controls['record'].find('input').prop('disabled', false)

  disableRecord: =>
    @controls['record'].addClass('disabled')
    @controls['record'].find('input').prop('disabled', true)

  startRecord: =>
    if @micRunning
      @controls['record'].find('i.circle-on').addClass("active")
      @workspace.currentTrack.reset()
      @isRecording = true 

  stopRecord: =>
    @isRecording = false
    $("div.record i").removeClass("active")
    $('div.playback').removeClass('disabled')
    @workspace.currentTrack.saveBuffers()
    console.log "duration: ", @workspace.currentTrack.duration

  enablePlayback: =>
    @controls['playback'].removeClass('disabled')
    @controls['playback'].find('input').prop('disabled', false)

  disablePlayback: =>
    @controls['playback'].addClass('disabled')
    @controls['playback'].find('input').prop('disabled', true)

  startPlayback: =>
    $('div.playback i').addClass('active')
    @workspace.startPlayback()
    @isPlaying = true

  stopPlayback: =>
    $('div.playback i').removeClass('active')
    @workspace.stopPlayback()
    @isPlaying = false

  ############################################################################################################
  # Event Handling
  ############################################################################################################

  _setupClickHandlers: =>
    # Start Audio API
    @editor.find('input#power-on').on 'click', (event) =>
      target = $(event.currentTarget)
      if target.is(':checked')
        navigator.webkitGetUserMedia { audio: true }, (stream) =>
          @stream = stream
          @enableMicrophone()
          @enableMetronome()
        , (event) =>
          target.prop('checked', false)

    # Microphone Toggle
    @editor.find("input#microphone-on").on 'click', (event) =>
      if $(event.currentTarget).is(':checked')
        @startMicrophone()
      else
        @stopMicrophone()

    # Start Recording
    @editor.find("input#record-on").on 'click', (event) =>
      if $(event.currentTarget).is(':checked')
        @startRecord()
      else
        @stopRecord()

    # # Stop Recording
    # @editor.find("#rec-stop").on 'click', (event) =>
    #   @stopRecording()

    # # Start Playback
    # @editor.find("#play-start").on 'click', (event) =>
    #   @startPlayback()

    # # Stop Playback
    # @editor.find('#play-stop').on 'click', (event) =>
    #   @stopPlayback()

    # Add Track
    @editor.find('#add-track').on 'click', (event) =>
      event.preventDefault()
      @workspace.createTrack()

    # Change Track Name
    $(document).on 'click', '.track .title', (event) =>
      event.preventDefault()

