####################################################
# TRAX.Editor
#   CoffeeScript "class" defining the Editor object.
#
####################################################

# Not Recording :: Microphone -> VolumeNode -> AnalyserNode -> ScriptProcessor -> Destination
#
# Recording :: Microphone -> VolumeNode -> AnalyserNode -> ScriptProcessor -> Recorder -> Destination

@TRAX ||= {}
@TRAX.Editor = class Editor

  track: undefined
  tracks: []

  constructor: (editor, options) ->
    @editor = editor
    @workspace = @editor.find('#workspace')
    @liveWaveform = @editor.find('#live-waveform')

    @bufferSize = 2048
    @sampleRate = 44100
    @bufferSource = undefined
    @currentTrackId = 0

    [@micRunning, @isRecording, @isPlaying] = [false, false, false]
    [@width, @height, @cursorPosition] = [0, 0, 0]
    @chromaOrange = new chroma.scale(["#00ff00", "#e0e000", "#ff7f00", "#b60101"])
    
    # Setup Web Audio API Context
    @context = new webkitAudioContext()

    @_setupNodes()
    @_setupAudioHandler()
    @_setupClickHandlers()
    @_drawGrid()

    # Create a track to start
    @_addTrack()

  ############################################################################################################
  # Web Audio API   
  ############################################################################################################

  _setupNodes: =>
    # Script Processer Node
    # This interface is an AudioNode which can generate, process, or analyse audio directly using JavaScript.
    # https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/specification.html#ScriptProcessorNode
    @scriptProcessor = @context.createScriptProcessor(2048, 1, 1)
    @scriptProcessor.connect(@context.destination)

    # Analyser Node
    # This interface represents a node which is able to provide real-time frequency and time-domain 
    # analysis information. The audio stream will be passed un-processed from input to output.
    # https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/specification.html#AnalyserNode-section
    @analyser = @context.createAnalyser()
    @analyser.smoothingTimeConstant = 0
    @analyser.fftSize = 512
    @analyser.connect(@scriptProcessor)

    # Gain Node
    # This interface is an AudioNode with a single input and single output. It multiplies the input audio 
    # signal by the (possibly time-varying) gain attribute, copying the result to the output. By default, 
    # it will take the input and pass it through to the output unchanged, which represents a constant gain 
    # change of 1.
    # https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/specification.html#GainNode
    @gain = @context.createGain()
    @gain.connect(@analyser)

  ############################################################################################################
  # Audio Processing   
  ############################################################################################################

  # AudioProcessingEvent Interface
  # This is an Event object which is dispatched to ScriptProcessorNode nodes. The event handler processes 
  # audio from the input (if any) by accessing the audio data from the inputBuffer attribute. The audio data 
  # which is the result of the processing (or the synthesized data if there are no inputs) is then placed into
  # the outputBuffer.
  # https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/specification.html#AudioProcessingEvent-section
  _setupAudioHandler: =>
    @scriptProcessor.onaudioprocess = (event) =>
      array = new Uint8Array(@analyser.frequencyBinCount)
      @analyser.getByteTimeDomainData(array)

      if @micRunning
        @_drawLiveWaveform(array) 

      if @isRecording
        
        @_drawRecording(array)
        leftChannel = event.inputBuffer.getChannelData(0)
        rightChannel = event.inputBuffer.getChannelData(0)

        # we clone the samples
        @track.leftChannel.push(new Float32Array(leftChannel))
        @track.rightChannel.push(new Float32Array(rightChannel))
        @track.length += @bufferSize;
     
      if @isPlaying
        console.log "it's playing!"

  ############################################################################################################
  # HTML5 Canvases   
  ############################################################################################################

  _drawGrid: =>
    width = @editor.find('#workspace #tracks td.canvases').width()
    height = @editor.find('#workspace #tracks').height()

    grid = @editor.find('#canvas-layer .canvases #grid')
    ctx = grid[0].getContext("2d")
    ctx.canvas.width = width
    ctx.canvas.height = height-6  # padding is 3px top+bottom
    ctx.save()

    for i in [0..width]
      if (i%100 is 0 && i isnt 0 && i isnt width)
        ctx.fillStyle = "#333333"
        ctx.fillRect(i, 0, 1, height)

  _drawLiveWaveform: (array) =>
    ctx = @liveWaveform[0].getContext("2d")
    ctx.clearRect(0, 0, 100, 35)

    for i in [0..array.length]
      value = array[i]
      ctx.fillStyle = @chromaOrange(value / 255).hex()
      ctx.fillRect((i * 100) / 255, (value / 2) - 45, 1, 1)

  _drawWaveform: (array) =>
    ctx = @track['canvases']['wave'][0].getContext("2d")
    waveValues = []
    min = Math.min.apply(Math, array) * 100 / 255
    max = Math.max.apply(Math, array) * 100 / 255
    while min < max
      waveValues.push(min)
      min++

    for i in [0..waveValues.length]
      value = waveValues[i]
      ctx.fillStyle = "#{@track.color()}"
      ctx.fillRect(0, value, 1, 1)
    ctx.translate(1, 0)

  _drawBackground: =>
    ctx = @track['canvases']['background'][0].getContext("2d")
    ctx.fillStyle = "rgba(255,255,255,0.1)"
    ctx.fillRect(0, 0, 1, @track['height'])
    ctx.translate(1, 0)
    @cursorPosition++

  _drawRecording: (array) =>
    @_drawWaveform(array)
    @_drawBackground()

  ############################################################################################################
  # Editor Methods   
  ############################################################################################################

  _trackCount: =>
    @workspace.find('#tracks .track').length

  _addTrack: =>
    $.get '/editor/add-track', (data) =>
      @workspace.find('#tracks tbody').append(data['html'])       
      @currentTrackId = @_trackCount()
      track = @workspace.find('#tracks .track:last')
      @tracks.push(new TRAX.Track(track, @currentTrackId))
      @_drawGrid()
      @_selectTrack(track)

  _resetTrack: =>
    # Reset Details
    @track.leftChannel.length = @track.rightChannel.length = @track.length = 0

    # Reset Track Canvas
    for id, element of @track['canvases']
      ctx = element[0].getContext("2d")
      ctx.save()
      ctx.setTransform(1, 0, 0, 1, 0, 0);
      ctx.clearRect(0, 0, ctx.canvas.width, 100);
      ctx.restore()

    # FIXME: Reset the Cursor
    # wave = @track['canvases']['wave'][0].getContext("2d")
    # wave.translate(-@currentPosition, 0);
    # wave.restore()
  
  _selectTrack: (target) =>
    @currentTrackId = target.prop('id').slice(-1)
    @track = @tracks[@currentTrackId-1]
    @editor.find('.track').removeClass('active')
    target.addClass('active')

  ############################################################################################################
  # Event Handling
  ############################################################################################################

  _setupClickHandlers: =>
    # Start Microphone
    @editor.find("#mic-start").on 'click', (event) =>
      navigator.webkitGetUserMedia { audio: true }, (stream) =>
        @micSource = @context.createMediaStreamSource(stream)
        @micSource.connect(@gain)
        @micRunning = true
        $("nav .record").removeClass("disabled")

    # Stop Microphone
    @editor.find("#mic-stop").on 'click', (event) =>
      @micSource.disconnect(@volume)
      @micRunning = false
      $("#live-waveform").get()[0].getContext("2d").clearRect(0, 0, 100, 35)
      $(".navbar .record").addClass("disabled")

    # Start Recording
    @editor.find("#rec-start").on 'click', (event) =>
      if !$(this).closest("div.record").hasClass("disabled")
        $("div.record i").addClass("active")
        # Reset Track Canvas
        @_resetTrack()
        @_drawGrid()
        # Reset the buffers for the new recording
        @track.leftChannel.length = @track.rightChannel.length = 0
        @track.length = 0       
        @isRecording = true 

    # Stop Recording
    @editor.find("#rec-stop").on 'click', (event) =>
      $("div.record i").removeClass("active")
      $('div.playback').removeClass('disabled')
      @track.stopRecording()
      @isRecording = false

    # Start Playback
    @editor.find("#play-start").on 'click', (event) =>
      $('div.playback i').addClass('active')
      @bufferSource = @context.createBufferSource()
      @bufferSource.buffer = @context.createBuffer(1, @track['buffers'][0].length, 44100)
      @bufferSource.buffer.getChannelData(0).set(@track['buffers'][0])
      @bufferSource.buffer.getChannelData(0).set(@track['buffers'][1])
      @bufferSource.onended = => @editor.find('#play-stop').click()
      @bufferSource.connect(@context.destination)
      @bufferSource.noteOn(0)
      @isPlaying = true

    # Stop Playback
    @editor.find('#play-stop').on 'click', (event) =>
      $('div.playback i').removeClass('active')
      @bufferSource.disconnect(@context.destination)
      @isPlaying = false

    # Add Track
    @editor.find('#add-track').on 'click', (event) =>
      event.preventDefault()
      @_addTrack()

    # Change Track Name
    $(document).on 'click', '.track .title', (event) =>
      event.preventDefault()

    # Select Track
    $(document).on 'click', '.track .panel', (event) =>
      event.preventDefault()
      target = $(event.currentTarget).closest('.track')
      @_selectTrack(target)

